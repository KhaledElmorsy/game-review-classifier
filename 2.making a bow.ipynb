{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a random sample from the data and write it to a new file to avoid loading the complete data set each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(r'data\\processed\\reviews_processed.csv')\n",
    "\n",
    "df = df.sample(n = 100000)\n",
    "\n",
    "df.to_csv(r'data\\samples\\sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write an algorithm to create a list of the unique words in all the reivews in the sample and the count of each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          word count\n",
      "0         this   347\n",
      "1         game   618\n",
      "2           is   410\n",
      "3        great    72\n",
      "4            i   501\n",
      "...        ...   ...\n",
      "3990  againand     2\n",
      "3991      goty     1\n",
      "3992      woah     1\n",
      "3993   morning     1\n",
      "3994   consume     1\n",
      "\n",
      "[3995 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(r'data\\samples\\sample.csv', nrows=600)\n",
    "\n",
    "wc = pd.DataFrame(columns = ['word','count'])\n",
    "\n",
    "test.dropna(inplace=True)\n",
    "\n",
    "a = 0\n",
    "\n",
    "for row, entry in test.iterrows():\n",
    "    for word in entry['review'].split():\n",
    "        if word in wc['word'].values:\n",
    "            wc.loc[wc['word']==word,'count']+=1\n",
    "        else:\n",
    "            wc.loc[len(wc)] = [word,1]\n",
    "print (wc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm above, while functional, was too slow to run for big data sets. I optimized it by reducing the number of operations as shown in the code below, but it was still taking too long when scaled to tens of thousands of reviews. So, in the next parts I used Scikit Learn's optimized text vectorizers to speed up tokenization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is faster but not fast enough:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          word count\n",
      "0         this   347\n",
      "1         game   618\n",
      "2           is   410\n",
      "3        great    72\n",
      "4            i   501\n",
      "...        ...   ...\n",
      "3990  againand     2\n",
      "3991      goty     1\n",
      "3992      woah     1\n",
      "3993   morning     1\n",
      "3994   consume     1\n",
      "\n",
      "[3995 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(r'data\\samples\\sample.csv', nrows=600)\n",
    "\n",
    "wc = pd.DataFrame(columns = ['word','count'])\n",
    "\n",
    "test.dropna(inplace=True)\n",
    "\n",
    "a = 0\n",
    "\n",
    "for row, entry in test.iterrows():\n",
    "    for word in entry['review'].split():\n",
    "        try:\n",
    "            index = wc.loc[wc['word'] == word].index[0]\n",
    "            wc['count'].iloc[index] += 1\n",
    "        except:\n",
    "            wc.loc[len(wc)] = [word, 1]\n",
    "     \n",
    "print (wc)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9133d50dc87182ed154dd984b25012be9bb6762f92b1cab2f9ffcc6b9b06f1af"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
